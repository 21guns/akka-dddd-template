<html>

    <body>

    <div>
        <h2>Background</h2>
        <h3>Distributed Domain Driven Design</h3>
        <h3>CQRS/ES  Command Query Responsibility Segregation / Event Sourcing</h3>
        <p>This is a pattern that uses Command and Query objects to apply the <a href="http://en.wikipedia.org/wiki/Command%E2%80%93query_separation">CQS</a> principle
        for modifying and retrieving data.
        </p>

        <p>
            Event Sourcing is an architectural pattern in which state is tracked with an immutable event log instead of
            destructive updates (mutable).
        </p>
    </div>

    <div>
        <h2>Getting Started</h2>

        <p>To get this application going, you will need to:

            <ul>
                <li>Set up the datastore</li>
                <li>Boot the cluster nodes</li>
                <li>Boot the Http microservice node</li>
            </ul>

        </p>


        <h3>DataStore</h3>
        <p>This application requires a distributed journal. Storage backends for journals and snapshot stores are pluggable in Akka persistence. In this case we are using <a href="http://cassandra.apache.org/download/">Cassandra</a>.
            You can find other journal plugins <a href="http://akka.io/community/?_ga=1.264939791.1443869017.1408561680">here</a>.
        </p>
        <p>
            The datastore is specified in <b>application.conf</b>
        <pre><code>cassandra-journal.contact-points = ["127.0.0.1"]</code></pre>
        <pre><code>cassandra-snapshot-store.contact-points = ["127.0.0.1"]</code></pre>
        As you can see, the default is localhost. In a cloud deployment, you could add several addresses to a cassandra cluster.
        </p>


        <p>This application uses a simple domain to demonstrate CQRS and event sourcing with Akka Persistence. This domain is an online auction:</p>
        <pre><code>
final case class Bid(price:Double, buyer:String, timeStamp:Long)

final case class Auction(auctionId:String,
                         startTime:Long,
                         endTime:Long,
                         initialPrice:Double,
                         acceptedBids:List[Bid],
                         refusedBids:List[Bid],
                         ended:Boolean)
        </code></pre>
        <p>This is a distributed application, leveraging <b>Akka Cluster</b>.</p>

        <p>The <b>Command</b> path of this application is illustrated by the creation of an auction, and placing bids.</p>
        <p>The <b>Query</b> path of this application is illustrated by the querying of winning bid and bid history.</p>
        <p>In order to distribute and segregate these paths, we leverage  <b>Akka Cluster</b>, as well as <b>Cluster Sharding</b>.</p>
          <p>Cluster Sharding enables the  distribution of the command and query actors across several nodes in the cluster,
            supporting interaction using their logical identifier, without having to care about their physical location in the cluster.
        </p>

        <h3>Cluster Nodes</h3>
        <p></p>
        <p>You must first boot some cluster nodes (as many as you want). Running locally, these are distinguished by port  eg:[2551,2552,...].<br>
            This cluster must specify one or more <b>seed nodes</b> in
        <b>application.conf</b>
<pre><code>
akka.cluster {
seed-nodes = [
"akka.tcp://ClusterSystem@127.0.0.1:2551",
"akka.tcp://ClusterSystem@127.0.0.1:2552"]

auto-down-unreachable-after = 10s
}
</code></pre>
        </p>

        <p>
            The Cluster Nodes are bootstrapped in <b>ClusterNode.scala</b>.
        </p>

        <p>
            To boot each cluster node locally:
<pre><code>
sbt 'runMain com.boldradius.cqrs.ClusterNodeApp nodeIpAddress port'
</code></pre>
for example:
<pre><code>
sbt 'runMain com.boldradius.cqrs.ClusterNodeApp 127.0.0.1 2551'
</code></pre>
        </p>


        <h3>Http Microservice Node</h3>

        <p> The HTTP front end is implemented as a <b>Spray</b> microservice and is bootstrapped in <b>HttpApp.scala</b>.It participates in the Cluster, but as a proxy.</p>
          <p>  To run the microservice locally:
<pre><code>
sbt 'runMain com.boldradius.cqrs.HttpApp httpIpAddress httpPort akkaIpAddres akkaPort'
</code></pre>
for example:
<pre><code>
sbt 'runMain com.boldradius.cqrs.HttpApp 127.0.0.1 9000 127.0.0.1 0'
</code></pre>



        </p>
        <p>The HTTP API enables the user to:
            <ul>
                <li>Create an Auction</li>
                <li>Place a did</li>
                <li>Query for the current winning bid</li>
                <li>Query for the bid history</li>
            </ul>

            <h4>Create Auction</h4>
             <pre><code>
 POST http://127.0.0.1:9000/startAuction

 {"auctionId":"123",
 "start":"2015-01-20-16:25",
 "end":"2015-07-20-16:35",
 "initialPrice" : 2,
 "prodId" : "3"}
             </code></pre>

        <h4>Place Bid</h4>
             <pre><code>
POST http://127.0.0.1:9000/bid

{"auctionId":"123",
"buyer":"dave",
"bidPrice":6}
             </code></pre>

        <h4>Query for the current winning bid</h4>
             <pre><code>
GET http://localhost:8080/winningBid/123
             </code></pre>


        <h4>Query for the bid history</h4>
             <pre><code>
http://localhost:8080/bidHistory/123
             </code></pre>
        </p>


        <h3>Spray service fowards to the cluster</h3>
        The trait <b>HttpAuctionServiceRoute.scala</b> implements a route that takes ActorRefs (one for command and query) as input.
        Upon receiving an Http request, it either sends a command message to the <b>command</b> actor, or a query message to the <b>query</b> actor.


         <pre><code>
 def route(command: ActorRef, query:ActorRef) = {
     post {
        path("startAuction") {
            extract(_.request) { e =>
                entity(as[StartAuctionDto]) {
                    auction => onComplete(
                        (command ? StartAuctionCmd(auction.auctionId,....

         </code></pre>

    </div>

        <div>
            <h2>Exploring the Command path in the Cluster</h2>
            <p>The command path is implemented in <b>BidProcessor.scala</b>. This is a <b>PersistentActor</b> that receives commands:

<pre><code>
def initial: Receive = {
    case a@StartAuctionCmd(id, start, end, initialPrice, prodId) => ...
}

def takingBids(auctionId: String, startTime: Long, closeTime: Long): Receive = {
            case a@PlaceBidCmd(id, buyer, bidPrice) => ...
}
</code></pre>

and produces events, writing them to the event journal, and notifying the <b>Query</b> Path of the updated journal:

  <pre><code>
val event = AuctionStartedEvt(id, start, end, initialPrice, prodId)   // the event to be persisted
persistAsync(event) { evt =>                                          // block that will run once event has been written to journal
readRegion ! Update(await = true)                                   // update the Query path
auctionStateMaybe = startMaybeState(id, start, end, initialPrice)   // update internal state
...
}
  </code></pre>

            </p>
               This actor is cluster sharded on auctionId as follows:
            <pre><code>
val idExtractor: ShardRegion.IdExtractor = {
    case m: AuctionCmd => (m.auctionId, m)
}

val shardResolver: ShardRegion.ShardResolver = msg => msg match {
    case m: AuctionCmd => (math.abs(m.auctionId.hashCode) % 100).toString
}

val shardName: String = "BidProcessor"
            </code></pre>
            This means, there is only one instance of this actor in the cluster, and all commands with the same <b>auctionId</b> will
            be routed to the same actor.
            <p>
            <p>
             If this actor receives no commands for 1 minute, it will <b>passivate</b> ( a pattern enabling the parent to stop the actor, in order to reduce memory consumption without losing any commands it is currently processing):
              <pre><code>
/** passivate the entity when no activity */
context.setReceiveTimeout(1 minute)     // this will send a ReceiveTimeout message after one minute, if no other messages come in
        </code></pre>
            The timeout is handled in the <b>Passivation.scala</b> trait:
             <pre><code>
protected def withPassivation(receive: Receive): Receive = receive.orElse{
    // tell parent actor to send us a poisinpill
    case ReceiveTimeout => context.parent ! Passivate(stopMessage = PoisonPill)

    // stop
    case PoisonPill => context.stop(self)
}
             </code></pre>
            </p>
               If this actor fails, or is passivated, and then is required again (to handle a command), the cluster will spin it up, and it will replay the
            event journal, updating it's internal state:
              <pre><code>
def receiveRecover: Receive = {
    case evt: AuctionEvt => updateState(evt)

    case RecoveryCompleted => {
        auctionStateMaybe.fold[Unit]({}) { auctionState =>
            if (auctionState.ended)
                context.become(passivate(auctionClosed(auctionState.auctionId, auctionState.endTime)).orElse(unknownCommand))
            else{
                context.become(passivate(takingBids(auctionState.auctionId, auctionState.startTime, auctionState.endTime)).orElse(unknownCommand))
                }
            }
        }
}
              </code></pre>

            </p>

        </div>
    <div>
        <h2>Exploring the Query path in the Cluster</h2>
         The Queries are handled in a different Actor: <b>BidView.scala</b>. This is a <b>PersistentView</b> that handles query messages, or prompts from
        it's companion <b>PersistentActor</b> to update itself.
        <p>
            <b>BidView.scala</b> is linked to the <b>BidProcessor.scala</b> event journal via it's <b>persistenceId</b>
            <pre><code>
override val persistenceId: String = "BidProcessor" + "-" + self.path.name
    </code></pre>
        This means it has access to this event journal, and can maintain, and recover state from this journal.
        </p>
        <p>
            It is possible for a PersistentView to save it's own snapshots, but, in our case, it isn't required.
        </p>

        <p>
            This PersistentView is sharded in the same way the PersistentActor is:
             <pre><code>
val idExtractor: ShardRegion.IdExtractor = {
    case m : AuctionEvt => (m.auctionId,m)
    case m : BidQuery => (m.auctionId,m)
}

val shardResolver: ShardRegion.ShardResolver = {
    case m: AuctionEvt => (math.abs(m.auctionId.hashCode) % 100).toString
    case m: BidQuery => (math.abs(m.auctionId.hashCode) % 100).toString
}
        </code></pre>
        One could have used a different shard strategy here, but a consequence of the above strategy is that the Query Path will
        reside in the same Shard Region as the command path, reducing latency of the Update() message from Command to Query.
        </p>

        <p>
The PersistentView maintains the following model in memory:
<pre><code>
final case class BidState(auctionId:String,
                         start:Long,
                         end:Long,
                         product:Double,
                         acceptedBids:List[Bid],
                         rejectedBids:List[Bid],
                         closed:Boolean)
</code></pre>

        This model is sufficient to satisfy both queries: Winning Bid, and  Bid History:

      <pre><code>

  def auctionInProgress(currentState:BidState, prodId:String):Receive = {

    case  GetBidHistoryQuery(auctionId) =>  sender ! BidHistoryResponse(auctionId,currentState.acceptedBids)

    case  WinningBidPriceQuery(auctionId) =>
        currentState.acceptedBids.headOption.fold(
        sender ! WinningBidPriceResponse(auctionId,currentState.product))(b =>
        sender ! WinningBidPriceResponse(auctionId,b.price))

          ....

  }
      </code></pre>

        </p>
    </div>


    </body>

</html>